#!/usr/bin/env python3
"""
auto_maker_scraper.py â€“ 2025-09-08
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Carwow ã‹ã‚‰ â€œå…¨ãƒ¡ãƒ¼ã‚«ãƒ¼â€ ã®è‹±èª slug ã‚’æŠ½å‡ºã—ã€ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§
æ¨™æº–å‡ºåŠ›ã¸è¿”ã™ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ„ãƒ¼ãƒ«ã€‚

ãƒ»Python 3.9 ä»¥é™ / requests / beautifulsoup4 / lxml ãŒå¿…è¦
ãƒ»--short ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã‚‹ã¨ slug ç¾¤ã ã‘ã‚’ 1 è¡Œã§å‡ºåŠ›
  ï¼ˆGitHub Actions ã®ç’°å¢ƒå¤‰æ•°ç”¨é€”ï¼‰
"""

from __future__ import annotations

import argparse
import re
import sys
from typing import List, Set
from urllib.parse import urljoin, urlparse

import requests
from bs4 import BeautifulSoup

BASE      = "https://www.carwow.co.uk"
HEADERS   = {"User-Agent": "Mozilla/5.0 (carwow-auto-scraper/2025)"}
TIMEOUT   = 25
EXCLUDE   = {
    # æ±ç”¨ãƒšãƒ¼ã‚¸
    "news","review","reviews","blog","help","about","finance","lease","used",
    "sell","deals","search","compare","tools","electric","hybrid","suv","mpv",
    "hatchback","saloon","coupe","estate",
}

class MakerScraper:
    def __init__(self) -> None:
        self.session          = requests.Session()
        self.session.headers  = HEADERS.copy()
        self.makers: Set[str] = set()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ public
    def get_all(self) -> List[str]:
        self._from_brands()
        self._from_home()
        self._from_sitemap()
        return sorted(self._filter(self.makers))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers
    def _from_brands(self) -> None:
        print("ğŸ“‹  /brands ãƒšãƒ¼ã‚¸ã‚’èµ°æŸ»â€¦")
        try:
            soup = self._soup(f"{BASE}/brands")
            for a in soup.select('a[href*="/brands/"]'):
                self._add(a["href"])
        except Exception as e:
            print(f"  âœ— brands error: {e}")

    def _from_home(self) -> None:
        print("ğŸ   ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚’èµ°æŸ»â€¦")
        try:
            soup = self._soup(BASE)
            for a in soup.find_all("a", href=True):
                self._add(a["href"])
        except Exception as e:
            print(f"  âœ— home error: {e}")

    def _from_sitemap(self) -> None:
        print("ğŸ—ºï¸  ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ã‚’èµ°æŸ»â€¦")
        for sm in ("/sitemap.xml", "/sitemap_index.xml", "/robots.txt"):
            url = BASE + sm
            try:
                txt = self.session.get(url, timeout=TIMEOUT).text
            except Exception:
                continue
            for u in re.findall(r"https?://[^\s\"'<>]+", txt):
                self._add(u)

    def _add(self, href: str) -> None:
        slug = self._extract(href)
        if slug:
            self.makers.add(slug)

    def _extract(self, url: str) -> str:
        if url.startswith("/"):
            url = urljoin(BASE, url)
        try:
            part = urlparse(url).path.strip("/").split("/")[0].lower()
        except Exception:
            return ""
        return part if self._valid(part) else ""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ utility
    def _soup(self, url: str) -> BeautifulSoup:
        r = self.session.get(url, timeout=TIMEOUT)
        r.raise_for_status()
        return BeautifulSoup(r.text, "lxml")

    def _valid(self, name: str) -> bool:
        return (
            1 < len(name) < 20
            and name.isascii()
            and re.fullmatch(r"[a-z-]+", name)
            and name not in EXCLUDE
        )

    def _filter(self, items: Set[str]) -> List[str]:
        print(f"âœ…  æŠ½å‡ºãƒ¡ãƒ¼ã‚«ãƒ¼æ•°: {len(items)}")
        return list(items)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI
def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--short", action="store_true",
                    help="ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§ 1 è¡Œå‡ºåŠ› (CI ç”¨)")
    args = ap.parse_args()

    makers = MakerScraper().get_all()

    if args.short:
        print(" ".join(makers))
    else:
        print("\nğŸ“Š  å…¨ãƒ¡ãƒ¼ã‚«ãƒ¼ä¸€è¦§")
        for i, m in enumerate(makers, 1):
            print(f"{i:2d}. {m}")
        print("\nğŸ”§  ç’°å¢ƒå¤‰æ•°ç”¨:")
        print(f'MAKES_FOR_BODYMAP: "{" ".join(makers)}"')


if __name__ == "__main__":
    main()
